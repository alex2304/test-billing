# Test billing api

## Требования
- сроки и качество
- выполнение всех требований
- прокомментировать выбранное решение
- прокомментировать механизмы хранения и обработки данных
- оценить плюсы и минусы механизмов хранения и обработки данных

Условия:
- большое кол-во транзакций
- гарантировать высокую производительность апи
- консистентность данных в любой момент времени
- подъем по команде docker-compose

## Описание решения
Проект состоит из трёх сервисов: api с реализацией поставленной задачи, инстанс базы postgresql и adminer для подключения к postgres и просмотра содержимого БД.

Развернуть локально можно с помощью одной команды `docker-compose up`, подробнее - в секции "Инструкция по запуску".

### Выбор технологий и фреймворков 
В качестве фреймворка для создания api был выбран fast-api, так как он является быстрым, асинхронным, а также простым, лаконичным и удобным. Ещё один бонус fast-api - наличие документации в формате open-api/redoc из коробки.

В качестве хранилища данных была выбрана postgresql, так как эта субд имеет мощные механизмы работы с блокировками при выполнении параллельных запросов, а наша цель - консистентность данных. Ещё один фактор, что postgresql это надёжное и проверенное временем решение, с которым я знаком.

Для запуска юнит-тестов был выбран модуль pytest, так как это мощный инструмент с поддержкой множества расширений, и в каком-то смысле является стандартом в своей области.

### Решение проблемы согласованности данных
Проблема с консистентностью данных в нашем случае может возникнуть из-за того, что операции пополнения баланса и перевода средств не являются атомарными и состоят из нескольких этапов.  Например, операция перевода средств с одного кошелька на другой фактически состоит из трёх этапов:
- списать средства со счёта отправителя
- зачислить средства на счёт получателя
- сохранить информацию о проведенной транзакции

Вот примеры реальных ситуаций, которые при неверной реализации могут привести к потере согласованности данных:
- одновременное зачисление или списание средств может привести к потере одного из зачисления / списания (lost update)
- списание средств со счёта отправителя, чтение измененных данных в другом запросе, а затем откат (dirty read)

Чтобы гарантировать согласованность данных в нашем случае, нужно объединить выполнение операций в рамках одной транзакции, а также правильно поработать с блокировками.
 
В моей текущей реализации достаточно объединить операции в рамках одной транзакции и использовать уровень изолированности по-умолчанию: read committed. Дело в том, что операция UPDATE, изменяющая определенные столбцы в рамках транзакции, автоматически накладывает RowExclusiveLock на ту строку, в которой происходит изменение, до завершения транзакции. Это значит, что если другая транзакция попытается прочитать строку до завершения транзакции, то она прочитает старые данные (потому что транзакция не зафиксирована), а если попробует изменить заблокированную строку - то придется подождать до завершения первой транзакции. 

В более сложных случаях, когда требуется читать/изменять одни и те же данные последовательно несколько раз в рамках одной транзакции, потребуется изменить уровень изолированности транзакций как минимум на repeatable read, либо использовать в запросах `SELECT FOR UPDATE`, явно указывая, что строки нужно заблокировать. 
Иначе, если мы сначала сделаем обычный SELECT в рамках транзакции с уровнем Read committed, а потом сделаем update этих же данных - согласованность будет нарушена, так как в промежутке между select и update ничто не помешает параллельной транзакции выполнить изменения, которые не будут учитываться при таком обновлении.

В нашем случае, благодаря специфике предметной области, мы смогли добиться согласованности без повышения уровня изолированности транзакции. У такого подхода есть один минус - это (мизерный) шанс возникновения дедлока, если два пользователя умудрятся перевести деньги друг другу одновременно, и две параллельные транзакции будут ждать освобождения двух строк друг от друга.
Однако, такой дедлок распознается postgres, и в случае его возникновения одна из транзакций будет завершена, и сервер вернет 500 на один из запросов, в то время как второй успешно выполнится. В теории, можно добавить обработку этого кейса, автоматически повторяя транзакцию, если такое произошло.

Повышение уровня изолированности транзакций как альтернативное решение тоже не идеально, потому что при обнаружении параллельных обновлений, postgres завершает одну из транзакций с ошибкой, и придется добавлять ручную обработку этого случая, что может негативно сказаться на производительности.

### Решение проблемы производительности

При оптимизации производительности должен соблюдаться баланс между написанием производительного кода без явных провалов в производительности (не использовать 100500 запросов, экономить память, выполнять действия параллельно), и при этом без преждевременной оптимизации. 
Оптимизация конкретных узких мест должна производиться после тестирования на условиях, приближенных к реальным (в идеале), либо после обратной связи от продакшна / в результате разбора инцидентов.

Однако, на основе моего опыта можно выделить несколько общих мест, добавление которых должно в целом увеличить производительность существующего решения: 
- использовать uvloop в uvicorn (хотел добавить, но не удалось сбилдить под apline)
- использовать asyncpg connection pool 
- использовать prepared statements средствами asyncpg

## Инструкция по запуску
Требования для развертывания проекта:
- Свободные порты 8000 и 8080 (будут прокинуты порты из контейнеров для апи и адмайнера соответственно)
- Установленный docker и docker-compose, поддерживающий версию 3 синтаксиса.

Развернуть проект локально в одну строчку:
```shell
 docker-compose up -d
```

Будут подняты три docker-контейнера:
- test-billing_api
- test-postgres
- test-adminer

Во время сборки изображения для контейнера `test-billing_api` будут выполнены юнит-тесты из файла `test_routes`. 
Тесты покрывают работу эндпоинтов изолированно от базы данных (для имитации базы данных используется мок).

Во время первого создания контейнера будет выполнен sql скрипт для создания таблиц: `create_tables.sql`. 
Для повторной инициализации необходимо будет уничтожить контейнер `docker-compose down` и заново создать.  

Для подключения и просмотра содержимого бд можно использовать adminer. Креды для подключения совпадают с указанными в `api/env/docker.env`.
